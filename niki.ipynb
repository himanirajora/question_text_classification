{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/himani/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /Users/himani/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "# import string\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# python3 -m spacy download en\n",
    "\n",
    "# download stopwords and wordnet and punctuations\n",
    "\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"wordnet\")\n",
    "nltk.download(\"punkt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # train_test split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "#metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions    labels\n",
       "0  how did serfdom develop in and then leave russ...   unknown\n",
       "1  what films featured the character popeye doyle ?       what\n",
       "2  how can i find a list of celebrities ' real na...   unknown\n",
       "3  what fowl grabs the spotlight after the chines...      what\n",
       "4                   what is the full form of .com ?       what"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read raw file\n",
    "\n",
    "raw_file = pd.read_csv(\"LabelledData (1).txt\", sep = \",,,\", header = None)\n",
    "raw_file.columns = ['questions','labels']\n",
    "raw_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " what           607\n",
       " who            401\n",
       " unknown        272\n",
       " affirmation    104\n",
       " when            96\n",
       "  what            2\n",
       "  who             1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_file['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what           609\n",
       "who            402\n",
       "unknown        272\n",
       "affirmation    104\n",
       "when            96\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## remove trailing or leading spaces\n",
    "\n",
    "raw_file['labels'] = raw_file['labels'].apply(lambda x: x.strip())\n",
    "raw_file['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution of label class in train set')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a56ab70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### distribution of levels in labels in training set\n",
    "\n",
    "sns.set_color_codes()\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1, figsize = (18,6))\n",
    "\n",
    "sns.countplot('labels', data = raw_file,palette=\"Set2\", ax = ax1)\n",
    "ax1.set_xlabel(\"labels\", size = 15)\n",
    "plt.title(\"Distribution of label class in train set\", size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>labels</th>\n",
       "      <th>clean_ques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how did serfdom develop in and then leave russ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>how did serfdom develop in and then leave russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what films featured the character popeye doyle ?</td>\n",
       "      <td>what</td>\n",
       "      <td>what film featured the character popeye doyle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i find a list of celebrities ' real na...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>how can i find a list of celebrity real name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what fowl grabs the spotlight after the chines...</td>\n",
       "      <td>what</td>\n",
       "      <td>what fowl grab the spotlight after the chinese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is the full form of .com ?</td>\n",
       "      <td>what</td>\n",
       "      <td>what is the full form of com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions   labels  \\\n",
       "0  how did serfdom develop in and then leave russ...  unknown   \n",
       "1  what films featured the character popeye doyle ?      what   \n",
       "2  how can i find a list of celebrities ' real na...  unknown   \n",
       "3  what fowl grabs the spotlight after the chines...     what   \n",
       "4                   what is the full form of .com ?      what   \n",
       "\n",
       "                                          clean_ques  \n",
       "0   how did serfdom develop in and then leave russia  \n",
       "1      what film featured the character popeye doyle  \n",
       "2       how can i find a list of celebrity real name  \n",
       "3  what fowl grab the spotlight after the chinese...  \n",
       "4                       what is the full form of com  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clean questions\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "def clean_tokenize(document):\n",
    "    document = re.sub('[^\\w_\\s-]', ' ',document)       #remove punctuation marks and other symbols\n",
    "    tokens = nltk.word_tokenize(document)              #Tokenize sentences\n",
    "    cleaned_article = \" \".join(lemma.lemmatize(item) for item in tokens)\n",
    "    return cleaned_article\n",
    "\n",
    "raw_file['clean_ques'] = raw_file['questions'].apply(clean_tokenize)\n",
    "raw_file.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create features from questions\n",
    "- WH-word\n",
    "- WH word POS\n",
    "- pos of word next to WH word\n",
    "- Root POS: The part of speech of the word at the root of the dependency parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how did serfdom develop in and then leave russia'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_file['clean_ques'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nlp(raw_file['clean_ques'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[what film featured the character popeye doyle]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{83: 'ADJ', 89: 'DET', 91: 'NOUN', 99: 'VERB'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = {w.pos: w.pos_ for w in x}\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what ADJ\n",
      "film NOUN\n",
      "featured VERB\n",
      "the DET\n",
      "character NOUN\n",
      "popeye NOUN\n",
      "doyle NOUN\n"
     ]
    }
   ],
   "source": [
    "for word in list(x.sents)[0]:\n",
    "    print(word, word.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>root_token</th>\n",
       "      <th>wh_bi_gram</th>\n",
       "      <th>wh_nbor_pos</th>\n",
       "      <th>wh_pos</th>\n",
       "      <th>wh_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VB</td>\n",
       "      <td>[how, did]</td>\n",
       "      <td>VBD</td>\n",
       "      <td>WRB</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBD</td>\n",
       "      <td>[what, film]</td>\n",
       "      <td>NN</td>\n",
       "      <td>WDT</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VB</td>\n",
       "      <td>[how, can]</td>\n",
       "      <td>MD</td>\n",
       "      <td>WRB</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VBP</td>\n",
       "      <td>[what, fowl]</td>\n",
       "      <td>NN</td>\n",
       "      <td>WDT</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>[what, is]</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>VBD</td>\n",
       "      <td>[what, contemptible]</td>\n",
       "      <td>JJ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VBD</td>\n",
       "      <td>[what, team]</td>\n",
       "      <td>NN</td>\n",
       "      <td>WDT</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>[what, is]</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VBP</td>\n",
       "      <td>[what, are]</td>\n",
       "      <td>VBP</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VB</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>VBP</td>\n",
       "      <td>[when, wa, wa, ozzy]</td>\n",
       "      <td>VBP</td>\n",
       "      <td>WDT</td>\n",
       "      <td>wa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RB</td>\n",
       "      <td>[why, do]</td>\n",
       "      <td>VBP</td>\n",
       "      <td>WRB</td>\n",
       "      <td>why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>WP</td>\n",
       "      <td>[who, wa]</td>\n",
       "      <td>IN</td>\n",
       "      <td>WP</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>VBD</td>\n",
       "      <td>[who, killed]</td>\n",
       "      <td>VBD</td>\n",
       "      <td>WP</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>VBN</td>\n",
       "      <td>[what, is]</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>VB</td>\n",
       "      <td>[what, sprawling]</td>\n",
       "      <td>VBG</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NN</td>\n",
       "      <td>[what, did]</td>\n",
       "      <td>VBD</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VBN</td>\n",
       "      <td>[how, many]</td>\n",
       "      <td>JJ</td>\n",
       "      <td>WRB</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>[what, is]</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>[what, is]</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>WP</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   root_token            wh_bi_gram wh_nbor_pos wh_pos wh_word\n",
       "0          VB            [how, did]         VBD    WRB     how\n",
       "1         VBD          [what, film]          NN    WDT    what\n",
       "2          VB            [how, can]          MD    WRB     how\n",
       "3         VBP          [what, fowl]          NN    WDT    what\n",
       "4         VBZ            [what, is]         VBZ     WP    what\n",
       "5         VBD  [what, contemptible]          JJ     WP    what\n",
       "6         VBD          [what, team]          NN    WDT    what\n",
       "7         VBZ            [what, is]         VBZ     WP    what\n",
       "8         VBP           [what, are]         VBP     WP    what\n",
       "9          VB                    []                           \n",
       "10        VBP  [when, wa, wa, ozzy]         VBP    WDT      wa\n",
       "11         RB             [why, do]         VBP    WRB     why\n",
       "12         WP             [who, wa]          IN     WP     who\n",
       "13        VBD         [who, killed]         VBD     WP     who\n",
       "14        VBN            [what, is]         VBZ     WP    what\n",
       "15         VB     [what, sprawling]         VBG     WP    what\n",
       "16         NN           [what, did]         VBD     WP    what\n",
       "17        VBN           [how, many]          JJ    WRB     how\n",
       "18        VBZ            [what, is]         VBZ     WP    what\n",
       "19        VBZ            [what, is]         VBZ     WP    what"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_list = []\n",
    "def pos_question(row):\n",
    "    \n",
    "    # get linguistic annotations of question\n",
    "    en_row = nlp(u''+ row)\n",
    "    sent_list = list(en_row.sents)\n",
    "    wh_bi_gram = []\n",
    "    root_token = \"\"\n",
    "    wh_pos = \"\"\n",
    "    wh_nbor_pos = \"\"\n",
    "    wh_word = \"\"\n",
    "    \n",
    "    for token in sent_list[0]:\n",
    "        if token.tag_ == \"WDT\" or token.tag_ == \"WP\" or token.tag_ == \"WP$\" or token.tag_ == \"WRB\":\n",
    "            wh_pos = token.tag_\n",
    "            wh_word = token.text\n",
    "            wh_bi_gram.append(token.text)\n",
    "            try:\n",
    "                wh_bi_gram.append(str(en_row[token.i + 1]))\n",
    "                wh_nbor_pos = en_row[token.i + 1].tag_\n",
    "            except IndexError:\n",
    "                wh_bi_gram.append(str(en_row[token.i]))\n",
    "                wh_nbor_pos = en_row[token.i].tag_\n",
    "        if token.dep_ == \"ROOT\":\n",
    "            root_token = token.tag_\n",
    "    pos_list.append({'wh_pos':wh_pos, 'wh_word': wh_word, 'wh_bi_gram':wh_bi_gram,\n",
    "                         'wh_nbor_pos':wh_nbor_pos, 'root_token':root_token})\n",
    "\n",
    "#apply function\n",
    "raw_file['clean_ques'].apply(pos_question)\n",
    "\n",
    "#convert list to dataframe\n",
    "pos_df = pd.DataFrame(pos_list)\n",
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concatnate labels column to pos_df\n",
    "\n",
    "final_data = pd.concat([pos_df,raw_file[['labels']]], axis =1)\n",
    "\n",
    "### one hot encoding of categorical variables and label encoding of labels\n",
    "\n",
    "cols = ['root_token','wh_nbor_pos','wh_pos','wh_word']\n",
    "X = pd.get_dummies(final_data[cols])\n",
    "X = X.values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(final_data['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "what           609\n",
       "who            402\n",
       "unknown        272\n",
       "affirmation    104\n",
       "when            96\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(model,X_train, X_test,y_train):\n",
    "    model_inst = model\n",
    "    model_inst.fit(X_train,y_train)\n",
    "    y_pred = model_inst.predict(X_test)\n",
    "    return y_pred\n",
    "    \n",
    "## evaluation metrics\n",
    "\n",
    "def get_performance_metrics(y_test,y_pred):\n",
    "    # Accuracy\n",
    "    global model_accuracy\n",
    "    model_accuracy = accuracy_score(y_test,y_pred)\n",
    "    print(\"Accuracy is \", model_accuracy)\n",
    "\n",
    "    # precision, recall, f1 score\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_test,y_pred)\n",
    "    print('Precision for each class is ', model_precision)\n",
    "    print('Recall/sensitivity for each class is ', model_recall)\n",
    "    print('F1 Score for each class is ', model_f1)\n",
    "\n",
    "    # confusion matrix\n",
    "    model_confusion_matrix = confusion_matrix(y_test,y_pred)\n",
    "    print('confusion matrix is :-->')\n",
    "    print(model_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics for Naive bayes model in 0- Fold: \n",
      "\n",
      "Accuracy is  0.911111111111\n",
      "Precision for each class is  [ 0.86486486  0.91025641  0.88687783  0.75        1.        ]\n",
      "Recall/sensitivity for each class is  [ 0.91428571  0.78021978  0.96551724  0.65625     0.97761194]\n",
      "F1 Score for each class is  [ 0.88888889  0.84023669  0.9245283   0.7         0.98867925]\n",
      "confusion matrix is :-->\n",
      "[[ 32   3   0   0   0]\n",
      " [  5  71  12   3   0]\n",
      " [  0   3 196   4   0]\n",
      " [  0   0  11  21   0]\n",
      " [  0   1   2   0 131]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Logistic Regression in 0- Fold: \n",
      "\n",
      "Accuracy is  0.931313131313\n",
      "Precision for each class is  [ 0.86486486  0.93975904  0.92093023  0.75        1.        ]\n",
      "Recall/sensitivity for each class is  [ 0.91428571  0.85714286  0.97536946  0.65625     0.98507463]\n",
      "F1 Score for each class is  [ 0.88888889  0.89655172  0.94736842  0.7         0.9924812 ]\n",
      "confusion matrix is :-->\n",
      "[[ 32   3   0   0   0]\n",
      " [  5  78   5   3   0]\n",
      " [  0   1 198   4   0]\n",
      " [  0   0  11  21   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Decision Tree model in 0- Fold: \n",
      "\n",
      "Accuracy is  0.925252525253\n",
      "Precision for each class is  [ 0.86486486  0.92857143  0.91203704  0.79310345  0.99224806]\n",
      "Recall/sensitivity for each class is  [ 0.91428571  0.85714286  0.97044335  0.71875     0.95522388]\n",
      "F1 Score for each class is  [ 0.88888889  0.89142857  0.94033413  0.75409836  0.97338403]\n",
      "confusion matrix is :-->\n",
      "[[ 32   3   0   0   0]\n",
      " [  5  78   5   3   0]\n",
      " [  0   2 197   3   1]\n",
      " [  0   0   9  23   0]\n",
      " [  0   1   5   0 128]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Random Forest model in 0- Fold: \n",
      "\n",
      "Accuracy is  0.935353535354\n",
      "Precision for each class is  [ 0.86486486  0.93975904  0.92957746  0.79310345  0.9924812 ]\n",
      "Recall/sensitivity for each class is  [ 0.91428571  0.85714286  0.97536946  0.71875     0.98507463]\n",
      "F1 Score for each class is  [ 0.88888889  0.89655172  0.95192308  0.75409836  0.98876404]\n",
      "confusion matrix is :-->\n",
      "[[ 32   3   0   0   0]\n",
      " [  5  78   5   3   0]\n",
      " [  0   1 198   3   1]\n",
      " [  0   0   9  23   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for SVC model in 0- Fold: \n",
      "\n",
      "Accuracy is  0.923232323232\n",
      "Precision for each class is  [ 0.86486486  0.87777778  0.92788462  0.75        1.        ]\n",
      "Recall/sensitivity for each class is  [ 0.91428571  0.86813187  0.95073892  0.65625     0.98507463]\n",
      "F1 Score for each class is  [ 0.88888889  0.87292818  0.93917275  0.7         0.9924812 ]\n",
      "confusion matrix is :-->\n",
      "[[ 32   3   0   0   0]\n",
      " [  5  79   4   3   0]\n",
      " [  0   6 193   4   0]\n",
      " [  0   1  10  21   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Naive bayes model in 1- Fold: \n",
      "\n",
      "Accuracy is  0.939393939394\n",
      "Precision for each class is  [ 0.92105263  0.98717949  0.93301435  0.89655172  0.93617021]\n",
      "Recall/sensitivity for each class is  [ 1.          0.84615385  0.96059113  0.8125      0.98507463]\n",
      "F1 Score for each class is  [ 0.95890411  0.9112426   0.94660194  0.85245902  0.96      ]\n",
      "confusion matrix is :-->\n",
      "[[ 35   0   0   0   0]\n",
      " [  3  77   7   0   4]\n",
      " [  0   0 195   3   5]\n",
      " [  0   1   5  26   0]\n",
      " [  0   0   2   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Logistic Regression in 1- Fold: \n",
      "\n",
      "Accuracy is  0.955555555556\n",
      "Precision for each class is  [ 0.92105263  0.97674419  0.97014925  0.9         0.94285714]\n",
      "Recall/sensitivity for each class is  [ 1.          0.92307692  0.96059113  0.84375     0.98507463]\n",
      "F1 Score for each class is  [ 0.95890411  0.94915254  0.96534653  0.87096774  0.96350365]\n",
      "confusion matrix is :-->\n",
      "[[ 35   0   0   0   0]\n",
      " [  3  84   1   0   3]\n",
      " [  0   0 195   3   5]\n",
      " [  0   1   4  27   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Decision Tree model in 1- Fold: \n",
      "\n",
      "Accuracy is  0.953535353535\n",
      "Precision for each class is  [ 0.92105263  0.96511628  0.96534653  0.9         0.94964029]\n",
      "Recall/sensitivity for each class is  [ 1.          0.91208791  0.96059113  0.84375     0.98507463]\n",
      "F1 Score for each class is  [ 0.95890411  0.93785311  0.96296296  0.87096774  0.96703297]\n",
      "confusion matrix is :-->\n",
      "[[ 35   0   0   0   0]\n",
      " [  3  83   2   0   3]\n",
      " [  0   1 195   3   4]\n",
      " [  0   1   4  27   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Random Forest model in 1- Fold: \n",
      "\n",
      "Accuracy is  0.957575757576\n",
      "Precision for each class is  [ 0.92105263  0.97647059  0.96568627  0.93103448  0.94964029]\n",
      "Recall/sensitivity for each class is  [ 1.          0.91208791  0.97044335  0.84375     0.98507463]\n",
      "F1 Score for each class is  [ 0.95890411  0.94318182  0.96805897  0.8852459   0.96703297]\n",
      "confusion matrix is :-->\n",
      "[[ 35   0   0   0   0]\n",
      " [  3  83   2   0   3]\n",
      " [  0   0 197   2   4]\n",
      " [  0   1   4  27   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for SVC model in 1- Fold: \n",
      "\n",
      "Accuracy is  0.945454545455\n",
      "Precision for each class is  [ 0.92105263  0.96385542  0.94202899  0.89655172  0.95652174]\n",
      "Recall/sensitivity for each class is  [ 1.          0.87912088  0.96059113  0.8125      0.98507463]\n",
      "F1 Score for each class is  [ 0.95890411  0.91954023  0.95121951  0.85245902  0.97058824]\n",
      "confusion matrix is :-->\n",
      "[[ 35   0   0   0   0]\n",
      " [  3  80   6   0   2]\n",
      " [  0   1 195   3   4]\n",
      " [  0   1   5  26   0]\n",
      " [  0   1   1   0 132]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Naive bayes model in 2- Fold: \n",
      "\n",
      "Accuracy is  0.902636916836\n",
      "Precision for each class is  [ 0.89189189  0.89333333  0.93719807  0.58695652  0.96875   ]\n",
      "Recall/sensitivity for each class is  [ 0.97058824  0.74444444  0.95566502  0.84375     0.92537313]\n",
      "F1 Score for each class is  [ 0.92957746  0.81212121  0.94634146  0.69230769  0.94656489]\n",
      "confusion matrix is :-->\n",
      "[[ 33   1   0   0   0]\n",
      " [  4  67   6  11   2]\n",
      " [  0   3 194   4   2]\n",
      " [  0   3   2  27   0]\n",
      " [  0   1   5   4 124]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Logistic Regression in 2- Fold: \n",
      "\n",
      "Accuracy is  0.922920892495\n",
      "Precision for each class is  [ 0.89189189  0.92941176  0.90697674  0.82758621  0.97637795]\n",
      "Recall/sensitivity for each class is  [ 0.97058824  0.87777778  0.96059113  0.75        0.92537313]\n",
      "F1 Score for each class is  [ 0.92957746  0.90285714  0.93301435  0.78688525  0.95019157]\n",
      "confusion matrix is :-->\n",
      "[[ 33   1   0   0   0]\n",
      " [  4  79   5   1   1]\n",
      " [  0   4 195   2   2]\n",
      " [  0   1   7  24   0]\n",
      " [  0   0   8   2 124]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Decision Tree model in 2- Fold: \n",
      "\n",
      "Accuracy is  0.916835699797\n",
      "Precision for each class is  [ 0.86842105  0.86666667  0.92307692  0.83333333  0.98347107]\n",
      "Recall/sensitivity for each class is  [ 0.97058824  0.86666667  0.94581281  0.9375      0.8880597 ]\n",
      "F1 Score for each class is  [ 0.91666667  0.86666667  0.93430657  0.88235294  0.93333333]\n",
      "confusion matrix is :-->\n",
      "[[ 33   1   0   0   0]\n",
      " [  5  78   6   1   0]\n",
      " [  0   6 192   3   2]\n",
      " [  0   1   1  30   0]\n",
      " [  0   4   9   2 119]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for Random Forest model in 2- Fold: \n",
      "\n",
      "Accuracy is  0.922920892495\n",
      "Precision for each class is  [ 0.89189189  0.87356322  0.94607843  0.76315789  0.97637795]\n",
      "Recall/sensitivity for each class is  [ 0.97058824  0.84444444  0.95073892  0.90625     0.92537313]\n",
      "F1 Score for each class is  [ 0.92957746  0.85875706  0.94840295  0.82857143  0.95019157]\n",
      "confusion matrix is :-->\n",
      "[[ 33   1   0   0   0]\n",
      " [  4  76   7   2   1]\n",
      " [  0   5 193   3   2]\n",
      " [  0   1   2  29   0]\n",
      " [  0   4   2   4 124]]\n",
      "---------------------------------------------------------\n",
      "\n",
      "Performance metrics for SVC model in 2- Fold: \n",
      "\n",
      "Accuracy is  0.922920892495\n",
      "Precision for each class is  [ 0.89189189  0.82474227  0.96428571  0.78378378  0.98412698]\n",
      "Recall/sensitivity for each class is  [ 0.97058824  0.88888889  0.93103448  0.90625     0.92537313]\n",
      "F1 Score for each class is  [ 0.92957746  0.85561497  0.94736842  0.84057971  0.95384615]\n",
      "confusion matrix is :-->\n",
      "[[ 33   1   0   0   0]\n",
      " [  4  80   5   1   0]\n",
      " [  0   9 189   3   2]\n",
      " [  0   1   2  29   0]\n",
      " [  0   6   0   4 124]]\n",
      "---------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## run models using stratified sampling\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, random_state = 5678)\n",
    "\n",
    "avg_acc_nb = []\n",
    "avg_acc_log = []\n",
    "avg_acc_dec = []\n",
    "avg_acc_ran =[]\n",
    "abg_acc_svm = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Naive bayes classifer\n",
    "    y_pred = run_models(MultinomialNB(),X_train, X_test,y_train)\n",
    "    print(\"Performance metrics for Naive bayes model in {0}- Fold: \\n\".format(i))\n",
    "    get_performance_metrics(y_test,y_pred)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    avg_acc_nb.append(model_accuracy)\n",
    "    \n",
    "    # Logistic classifier\n",
    "    y_pred = run_models(LogisticRegression(multi_class='multinomial',solver = 'lbfgs',\n",
    "                                           random_state = 5678),X_train, X_test,y_train)\n",
    "    print(\"Performance metrics for Logistic Regression in {0}- Fold: \\n\".format(i))\n",
    "    get_performance_metrics(y_test,y_pred)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    avg_acc_log.append(model_accuracy)\n",
    "    \n",
    "    # Decision Tree classifier\n",
    "    y_pred = run_models(DecisionTreeClassifier(random_state = 5678),X_train, X_test,y_train)\n",
    "    print(\"Performance metrics for Decision Tree model in {0}- Fold: \\n\".format(i))\n",
    "    get_performance_metrics(y_test,y_pred)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    avg_acc_dec.append(model_accuracy)\n",
    "    \n",
    "    # random Forest Classifier\n",
    "    y_pred = run_models(RandomForestClassifier(random_state = 5678),X_train, X_test,y_train)\n",
    "    print(\"Performance metrics for Random Forest model in {0}- Fold: \\n\".format(i))\n",
    "    get_performance_metrics(y_test,y_pred)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    avg_acc_ran.append(model_accuracy)\n",
    "\n",
    "    # Support vector machines\n",
    "    y_pred = run_models(SVC(random_state = 5678),X_train, X_test,y_train)\n",
    "    print(\"Performance metrics for SVC model in {0}- Fold: \\n\".format(i))\n",
    "    get_performance_metrics(y_test,y_pred)\n",
    "    print(\"---------------------------------------------------------\\n\")\n",
    "    abg_acc_svm.append(model_accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy in Naive Bayes: 0.917713989114\n",
      "Average accuracy in Logistic: 0.936596526455\n",
      "Average accuracy in Decision: 0.931874526195\n",
      "Average accuracy in Random Forest: 0.938616728475\n",
      "Average accuracy in SVC: 0.930535920394\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy in Naive Bayes:\", sum(avg_acc_nb)/len(avg_acc_nb))\n",
    "print(\"Average accuracy in Logistic:\", sum(avg_acc_log)/len(avg_acc_log))\n",
    "print(\"Average accuracy in Decision:\", sum(avg_acc_dec)/len(avg_acc_dec))\n",
    "print(\"Average accuracy in Random Forest:\", sum(avg_acc_ran)/len(avg_acc_ran))\n",
    "print(\"Average accuracy in SVC:\", sum(abg_acc_svm)/len(abg_acc_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
